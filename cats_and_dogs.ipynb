{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fcaa306",
   "metadata": {},
   "source": [
    "# Cats and dogs classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef51a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Евгений Артёменко\\PycharmProjects\\Projects\\Machine learning\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d0074",
   "metadata": {},
   "source": [
    "## Этап 1: Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1323dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_dir1:str, path_dir2:str):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.path_dir1 = path_dir1\n",
    "        self.path_dir2 = path_dir2\n",
    "        \n",
    "        self.dir1_list = sorted(os.listdir(path_dir1))\n",
    "        self.dir2_list = sorted(os.listdir(path_dir2))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dir1_list) + len(self.dir2_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if idx < len(self.dir1_list):\n",
    "            class_id = 0\n",
    "            img_path = os.path.join(self.path_dir1, self.dir1_list[idx])\n",
    "        else:\n",
    "            class_id = 1\n",
    "            idx -= len(self.dir1_list)\n",
    "            img_path = os.path.join(self.path_dir2, self.dir2_list[idx])\n",
    "        \n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "        \n",
    "        img = cv2.resize(img, (128, 128), interpolation=cv2.INTER_AREA)\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        \n",
    "        t_img = torch.from_numpy(img)\n",
    "        t_class_id = torch.tensor(class_id)\n",
    "        \n",
    "        return {'img': t_img, 'label': t_class_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "82d00c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dogs_path = 'training_set\\dogs'\n",
    "train_cats_path = 'training_set\\cats'\n",
    "\n",
    "test_dogs_path = 'test_set\\dogs'\n",
    "test_cats_path = 'test_set\\cats'\n",
    "\n",
    "train_ds = CatDogsDataset(train_dogs_path, train_cats_path)\n",
    "test_ds = CatDogsDataset(test_dogs_path, test_cats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "282f370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds[0]['img']\n",
    "# len(train_ds)\n",
    "# len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01daf4e1",
   "metadata": {},
   "source": [
    "## Этап 2: DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b6597b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=batch_size, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22742764",
   "metadata": {},
   "source": [
    "## Этап 3: Архитектура нейроннной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "07483a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.conv0 = nn.Conv2d(3, 128, 3, stride=1, padding=0)\n",
    "        self.conv1 = nn.Conv2d(128, 128, 3, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(128, 128, 3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, stride=1, padding=0)\n",
    "        \n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(256, 20)\n",
    "        self.linear2 = nn.Linear(20, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.activation(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.adaptivepool(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.linear2(out)\n",
    "                \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "693cb2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (activation): LeakyReLU(negative_slope=0.2)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (adaptivepool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=256, out_features=20, bias=True)\n",
       "  (linear2): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0535470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_loader:\n",
    "    img = sample['img']\n",
    "    img_id = sample['label']\n",
    "    model(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fcfd13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label):\n",
    "    answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1)\n",
    "    return answer.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b421d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f3363",
   "metadata": {},
   "source": [
    "## Этап 4: Обучение нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e7dea90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                          | 0/500 [00:00<?, ?it/s]D:\\Users\\Евгений Артёменко\\AppData\\Local\\Temp\\ipykernel_29396\\1416373963.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [10:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6970200011730194\n",
      "0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [26:43<00:00,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6867218539118767\n",
      "0.54875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [10:36<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6591896890997887\n",
      "0.613875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [25:53<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6269472041130066\n",
      "0.653875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [06:03<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.604771379351616\n",
      "0.672875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [06:16<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5805216165184974\n",
      "0.702625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [06:20<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5535449033379555\n",
      "0.71975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [06:34<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5203351802825927\n",
      "0.746875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [06:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48964941254258154\n",
      "0.7665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [07:32<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4531156561374664\n",
      "0.790875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_val = 0\n",
    "    acc_val = 0\n",
    "    for sample in (pbar := tqdm(train_loader)):\n",
    "        img, label = sample['img'], sample['label']\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        label = F.one_hot(label, 2).float()\n",
    "        pred = model(img)\n",
    "        \n",
    "        loss = loss_func(pred,label)\n",
    "        loss.backward()\n",
    "        loss_val += loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        acc_val += accuracy(pred, label)\n",
    "        \n",
    "    pbar.set_description(f'loss: {loss.item()} \\ accuracy: {accuracy(pred, label)}')\n",
    "    print(loss_val/len(train_loader))\n",
    "    print(acc_val/len(train_loader))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62867f4b",
   "metadata": {},
   "source": [
    "## Этап 5: Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val = 0\n",
    "acc_val = 0\n",
    "for sample in (pbar := tqdm(test_loader)):\n",
    "    with torch.no_grad():\n",
    "        img, label = sample['img'], sample['label']\n",
    "\n",
    "        label = F.one_hot(label, 2).float()\n",
    "        pred = model(img)\n",
    "\n",
    "        loss = loss_func(pred, label)\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "\n",
    "        acc_current = accuracy(pred, label)\n",
    "        acc_val += acc_current\n",
    "\n",
    "    pbar.set_description(f'loss: {loss_item:.5f}\\taccuracy: {acc_current:.3f}')\n",
    "print(loss_val/len(train_loader))\n",
    "print(acc_val/len(train_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
